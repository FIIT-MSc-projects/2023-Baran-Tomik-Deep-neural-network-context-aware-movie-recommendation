{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.metrics import RSquare\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision - MAP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from:\n",
    "# author: Ben Hamner\n",
    "# author's github: benhamner\n",
    "# link to github: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py \n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    apk_sum = 0.0\n",
    "    for user in actual:\n",
    "        if user in predicted:\n",
    "            apk_sum += apk(actual[user], predicted[user], k)\n",
    "\n",
    "    return apk_sum / len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank - MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(actual, predicted):\n",
    "    mrr_sum = 0.0\n",
    "    for user in actual:\n",
    "        if user in predicted:\n",
    "            rank = 1\n",
    "            for movie in predicted[user]:\n",
    "                if movie in actual[user]:\n",
    "                    mrr_sum += 1.0 / rank\n",
    "                    break\n",
    "                rank += 1\n",
    "    return mrr_sum / len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain - NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from: https://gist.github.com/tgsmith61591/d8aa96ac7c74c24b33e4b0cb967ca519\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Author: Taylor G Smith\n",
    "#\n",
    "# Recommender system ranking metrics derived from Spark source for use with\n",
    "# Python-based recommender libraries (i.e., implicit,\n",
    "# http://github.com/benfred/implicit/). These metrics are derived from the\n",
    "# original Spark Scala source code for recommender metrics.\n",
    "# https://github.com/apache/spark/blob/master/mllib/src/main/scala/org/apache/spark/mllib/evaluation/RankingMetrics.scala\n",
    "\n",
    "def _require_positive_k(k):\n",
    "    \"\"\"Helper function to avoid copy/pasted code for validating K\"\"\"\n",
    "    if k <= 0:\n",
    "        raise ValueError(\"ranking position k should be positive\")\n",
    "\n",
    "\n",
    "def _mean_ranking_metric(predictions, labels, k, metric):\n",
    "    \"\"\"Helper function for precision_at_k and mean_average_precision\"\"\"\n",
    "    # do not zip, as this will require an extra pass of O(N). Just assert\n",
    "    # equal length and index (compute in ONE pass of O(N)).\n",
    "    # if len(predictions) != len(labels):\n",
    "    #     raise ValueError(\"dim mismatch in predictions and labels!\")\n",
    "    # return np.mean([\n",
    "    #     metric(np.asarray(predictions[i]), np.asarray(labels[i]))\n",
    "    #     for i in xrange(len(predictions))\n",
    "    # ])\n",
    "\n",
    "    # Actually probably want lazy evaluation in case preds is a\n",
    "    # generator, since preds can be very dense and could blow up\n",
    "    # memory... but how to assert lengths equal? FIXME\n",
    "    return np.mean(\n",
    "        [\n",
    "            metric(np.asarray(prd), np.asarray(labels[i]), k)\n",
    "            for i, prd in enumerate(predictions)  # lazy eval if generator\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def _warn_for_empty_labels():\n",
    "    \"\"\"Helper for missing ground truth sets\"\"\"\n",
    "    print(\"Empty ground truth set! Check input data\")\n",
    "    return 0.0\n",
    "\n",
    "def ndcg_at(predictions, labels, k=10, assume_unique=True):\n",
    "    \"\"\"Compute the normalized discounted cumulative gain at K.\n",
    "\n",
    "    Compute the average NDCG value of all the queries, truncated at ranking\n",
    "    position k. The discounted cumulative gain at position k is computed as:\n",
    "\n",
    "        sum,,i=1,,^k^ (2^{relevance of ''i''th item}^ - 1) / log(i + 1)\n",
    "\n",
    "    and the NDCG is obtained by dividing the DCG value on the ground truth set.\n",
    "    In the current implementation, the relevance value is binary.\n",
    "\n",
    "    If a query has an empty ground truth set, zero will be used as\n",
    "    NDCG together with a warning.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    predictions : array-like, shape=(n_predictions,)\n",
    "        The prediction array. The items that were predicted, in descending\n",
    "        order of relevance.\n",
    "\n",
    "    labels : array-like, shape=(n_ratings,)\n",
    "        The labels (positively-rated items).\n",
    "\n",
    "    k : int, optional (default=10)\n",
    "        The rank at which to measure the NDCG.\n",
    "\n",
    "    assume_unique : bool, optional (default=True)\n",
    "        Whether to assume the items in the labels and predictions are each\n",
    "        unique. That is, the same item is not predicted multiple times or\n",
    "        rated multiple times.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # predictions for 3 users\n",
    "    >>> preds = [[1, 6, 2, 7, 8, 3, 9, 10, 4, 5],\n",
    "    ...          [4, 1, 5, 6, 2, 7, 3, 8, 9, 10],\n",
    "    ...          [1, 2, 3, 4, 5]]\n",
    "    >>> # labels for the 3 users\n",
    "    >>> labels = [[1, 2, 3, 4, 5], [1, 2, 3], []]\n",
    "    >>> ndcg_at(preds, labels, 3)\n",
    "    0.3333333432674408\n",
    "    >>> ndcg_at(preds, labels, 10)\n",
    "    0.48791273434956867\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] K. Jarvelin and J. Kekalainen, \"IR evaluation methods for\n",
    "           retrieving highly relevant documents.\"\n",
    "    \"\"\"\n",
    "    # validate K\n",
    "    _require_positive_k(k)\n",
    "\n",
    "    def _inner_ndcg(pred, lab, k=10):\n",
    "        if lab.shape[0]:\n",
    "            # if we do NOT assume uniqueness, the set is a bit different here\n",
    "            if not assume_unique:\n",
    "                lab = np.unique(lab)\n",
    "\n",
    "            n_lab = lab.shape[0]\n",
    "            n_pred = pred.shape[0]\n",
    "            n = min(max(n_pred, n_lab), k)  # min(min(p, l), k)?\n",
    "\n",
    "            # similar to mean_avg_prcsn, we need an arange, but this time +2\n",
    "            # since python is zero-indexed, and the denom typically needs +1.\n",
    "            # Also need the log base2...\n",
    "            arange = np.arange(n, dtype=np.float32)  # length n\n",
    "\n",
    "            # since we are only interested in the arange up to n_pred, truncate\n",
    "            # if necessary\n",
    "            arange = arange[:n_pred]\n",
    "            denom = np.log2(arange + 2.0)  # length n\n",
    "            gains = 1.0 / denom  # length n\n",
    "\n",
    "            # compute the gains where the prediction is present in the labels\n",
    "            dcg_mask = np.in1d(pred[:n], lab, assume_unique=assume_unique)\n",
    "            dcg = gains[dcg_mask].sum()\n",
    "\n",
    "            # the max DCG is sum of gains where the index < the label set size\n",
    "            max_dcg = gains[arange < n_lab].sum()\n",
    "            return dcg / max_dcg\n",
    "\n",
    "        else:\n",
    "            return _warn_for_empty_labels()\n",
    "\n",
    "    return _mean_ranking_metric(predictions, labels, k, _inner_ndcg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### Experiment 4 - 1m ###################\n",
    " \n",
    "# ## 1m No context\n",
    "# test_split_data_path = 'eval_data/test_split_1ml_no_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/1m_no_context/'\n",
    "# nn_model_path = '../model/experiment_4/arch5_1m_no_context_max_abs_scaler_gn_trained.keras'\n",
    "# scaler_file = '1m_no_context_scaler.pkl'\n",
    "\n",
    "# ## 1m MovieLens context\n",
    "# test_split_data_path = 'eval_data/test_split_1ml_movielens_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/1m_movielens_context/'\n",
    "# nn_model_path = '../model/experiment_4/arch5_1m_movielens_context_max_abs_scaler_gn_trained.keras'\n",
    "# scaler_file = '1m_movielens_context_scaler.pkl'\n",
    "\n",
    "# ## 1m Added IMDb context\n",
    "# test_split_data_path = 'eval_data/test_split_1ml_added_imdb_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/1m/'\n",
    "# nn_model_path = '../model/experiment_4/arch5_1m_added_imdb_context_max_abs_scaler_gn_trained.keras'\n",
    "# scaler_file = '1m_added_imdb_context_scaler.pkl'\n",
    "\n",
    "################### Experiment 4 - 25m ###################\n",
    "\n",
    "# ## 25m Added IMDb context\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_added_imdb_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m/'\n",
    "# nn_model_path = '../model/experiment_4/arch5_25m_added_imdb_context_max_abs_scaler_gn_trained.keras'\n",
    "# scaler_file = '25m_added_imdb_context_scaler.pkl'\n",
    "\n",
    "# ## 25m MovieLens context\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_movielens_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m_movielens_context/'\n",
    "# nn_model_path = '../model/experiment_4/arch5_25m_movielens_context_max_abs_scaler_gn_trained.keras'\n",
    "# scaler_file = '25m_movielens_context_scaler.pkl'\n",
    "\n",
    "# ## 25m No context\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_no_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m_no_context/'\n",
    "# nn_model_path = '../model/experiment_4/arch5_25m_no_context_max_abs_scaler_gn_trained.keras'\n",
    "# scaler_file = '25m_no_context_scaler.pkl'\n",
    "\n",
    "################### 25m - profiles ###################\n",
    "\n",
    "# ## 25m Added IMDb context - PROFILE 1\n",
    "# test_split_data_path = 'eval_data/test_split_profile_1.csv'\n",
    "# recsys_data_path = '../data/transform_data/profile_1/'\n",
    "# nn_model_path = '../model/profiles/arch10_25m_profile_1_gn_trained.keras'\n",
    "# scaler_file = 'scaler_profile_1.pkl'\n",
    "\n",
    "# ## 25m Added IMDb context - PROFILE 2\n",
    "# test_split_data_path = 'eval_data/test_split_profile_2.csv'\n",
    "# recsys_data_path = '../data/transform_data/profile_2/'\n",
    "# nn_model_path = '../model/profiles/arch10_25m_profile_2_gn_trained.keras'\n",
    "# scaler_file = 'scaler_profile_2.pkl'\n",
    "\n",
    "# ## 25m Added IMDb context - PROFILE 3\n",
    "# test_split_data_path = 'eval_data/test_split_profile_3.csv'\n",
    "# recsys_data_path = '../data/transform_data/profile_3/'\n",
    "# nn_model_path = '../model/profiles/arch10_25m_profile_3_gn_trained.keras'\n",
    "# scaler_file = 'scaler_profile_3.pkl'\n",
    "\n",
    "################### 25m - Achritecture 8 vs Achritecture 10 ###################\n",
    "\n",
    "# ## 25m Added IMDb context - Achritecture 8\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_added_imdb_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m/'\n",
    "# nn_model_path = '../model/arch8_arch10/arch8_25m_added_imdb_context_max_abs_scaler_hpt_gn_trained.keras'\n",
    "# scaler_file = '25m_added_imdb_context_scaler.pkl'\n",
    "\n",
    "# ## 25m Added IMDb context - Achritecture 10\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_added_imdb_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m/'\n",
    "# nn_model_path = '../model/arch8_arch10/arch10_25m_added_imdb_context_max_abs_scaler_gn_trained.keras'\n",
    "# scaler_file = '25m_added_imdb_context_scaler.pkl'\n",
    "\n",
    "\n",
    "################### FINAL ################### (25m Added IMDb context)\n",
    "\n",
    "test_split_data_path = 'eval_data/test_split_25ml_added_imdb_context.csv'\n",
    "recsys_data_path = '../data/transform_data/25m/'\n",
    "nn_model_path = '../model/global_recommending_model.keras'\n",
    "scaler_file = '25m_added_imdb_context_scaler.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>day</th>\n",
       "      <th>isWeekday</th>\n",
       "      <th>season</th>\n",
       "      <th>partOfDay</th>\n",
       "      <th>holiday</th>\n",
       "      <th>movieYear</th>\n",
       "      <th>titleType</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>...</th>\n",
       "      <th>genreNews</th>\n",
       "      <th>genreReality-tv</th>\n",
       "      <th>genreRomance</th>\n",
       "      <th>genreSci-fi</th>\n",
       "      <th>genreShort</th>\n",
       "      <th>genreSport</th>\n",
       "      <th>genreThriller</th>\n",
       "      <th>genreWar</th>\n",
       "      <th>genreWestern</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43093</td>\n",
       "      <td>1923</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58800</td>\n",
       "      <td>57669</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134109</td>\n",
       "      <td>69075</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141503</td>\n",
       "      <td>1663</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1981</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147198</td>\n",
       "      <td>1136</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498342</th>\n",
       "      <td>107639</td>\n",
       "      <td>3977</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498343</th>\n",
       "      <td>22136</td>\n",
       "      <td>2870</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498344</th>\n",
       "      <td>162047</td>\n",
       "      <td>7883</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1943</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498345</th>\n",
       "      <td>99479</td>\n",
       "      <td>54995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498346</th>\n",
       "      <td>141933</td>\n",
       "      <td>6754</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2498347 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         userId  movieId  day  isWeekday  season  partOfDay  holiday  \\\n",
       "0         43093     1923    3          1       2          4        3   \n",
       "1         58800    57669    3          1       1          2        2   \n",
       "2        134109    69075    5          1       2          4        3   \n",
       "3        141503     1663    5          1       4          1        2   \n",
       "4        147198     1136    4          1       4          4        2   \n",
       "...         ...      ...  ...        ...     ...        ...      ...   \n",
       "2498342  107639     3977    6          0       3          4        2   \n",
       "2498343   22136     2870    1          1       3          4        2   \n",
       "2498344  162047     7883    7          0       1          3        2   \n",
       "2498345   99479    54995    1          1       3          4        2   \n",
       "2498346  141933     6754    1          1       4          3        2   \n",
       "\n",
       "         movieYear  titleType  isAdult  ...  genreNews  genreReality-tv  \\\n",
       "0             1998          0        0  ...          0                0   \n",
       "1             2008          0        0  ...          0                0   \n",
       "2             1997          0        0  ...          0                0   \n",
       "3             1981          0        0  ...          0                0   \n",
       "4             1975          0        0  ...          0                0   \n",
       "...            ...        ...      ...  ...        ...              ...   \n",
       "2498342       2000          0        0  ...          0                0   \n",
       "2498343       1967          0        0  ...          0                0   \n",
       "2498344       1943          0        0  ...          0                0   \n",
       "2498345       2007          0        0  ...          0                0   \n",
       "2498346       2003          0        0  ...          0                0   \n",
       "\n",
       "         genreRomance  genreSci-fi  genreShort  genreSport  genreThriller  \\\n",
       "0                   1            0           0           0              0   \n",
       "1                   0            0           0           0              1   \n",
       "2                   0            0           0           0              0   \n",
       "3                   0            0           0           0              0   \n",
       "4                   0            0           0           0              0   \n",
       "...               ...          ...         ...         ...            ...   \n",
       "2498342             0            0           0           0              0   \n",
       "2498343             0            0           0           0              0   \n",
       "2498344             0            0           0           0              0   \n",
       "2498345             0            1           0           0              0   \n",
       "2498346             0            0           0           0              0   \n",
       "\n",
       "         genreWar  genreWestern  rating  \n",
       "0               0             0     4.0  \n",
       "1               0             0     4.5  \n",
       "2               0             0     2.5  \n",
       "3               1             0     4.5  \n",
       "4               0             0     3.5  \n",
       "...           ...           ...     ...  \n",
       "2498342         0             0     2.5  \n",
       "2498343         0             0     4.0  \n",
       "2498344         0             0     3.5  \n",
       "2498345         0             0     3.0  \n",
       "2498346         0             0     3.5  \n",
       "\n",
       "[2498347 rows x 42 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = pd.read_csv(test_split_data_path)\n",
    "test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of users to evaluate\n",
    "n_users = 10\n",
    "# number of recommendations to make\n",
    "top_k = 10\n",
    "# lowest rating to consider as a positive recommendation\n",
    "low_rating = 4.0\n",
    "\n",
    "# sort users by number of ratings\n",
    "test_ratings_all_users = test_ratings['userId'].value_counts().index.tolist()[:n_users]\n",
    "\n",
    "nn_model = load_model(nn_model_path, custom_objects={'RSquare': RSquare()}, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    # Load scaler\n",
    "    scaler = joblib.load(recsys_data_path + scaler_file)\n",
    "\n",
    "    # Return scaled data\n",
    "    return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 users IDs: [72315, 137293, 80974, 33844, 20055, 92046, 49403, 109731, 115102, 75309]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Top {n_users} users IDs: {test_ratings_all_users}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = {}\n",
    "predicted = {}\n",
    "\n",
    "for user_id in test_ratings_all_users:\n",
    "\n",
    "    user_test_ratings = test_ratings[test_ratings['userId'] == user_id]\n",
    "\n",
    "    actual_ratings = user_test_ratings[user_test_ratings['rating'] >= low_rating]\n",
    "    actual[user_id] = actual_ratings['movieId'].tolist()\n",
    "\n",
    "    scaled_user_test_ratings = scale_data(user_test_ratings.drop(['rating'], axis=1))\n",
    "    movie_indices = user_test_ratings['movieId'].values\n",
    "\n",
    "    predictions = nn_model.predict(scaled_user_test_ratings, verbose=0).flatten()\n",
    "\n",
    "    predicted_movies = pd.DataFrame({'movieId': movie_indices, 'rating': predictions})\n",
    "    predicted_movies = predicted_movies.sort_values(by='rating', ascending=False)\n",
    "    predicted[user_id] = predicted_movies['movieId'][:top_k].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MRR\n",
    "mrr_fin = mrr(actual, predicted)\n",
    "\n",
    "# MAP@K\n",
    "mapa3 = mapk(actual, predicted, 3)\n",
    "mapa10 = mapk(actual, predicted, 10)\n",
    "\n",
    "# NDCG@K\n",
    "p = [value for value in predicted.values()]\n",
    "a = [value for value in actual.values()]\n",
    "\n",
    "ndcga5 = ndcg_at(p, a , 5)\n",
    "ndcga10 = ndcg_at(p, a , 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR:      1.0\n",
      "MAP@3:    0.9\n",
      "MAP@10:   0.7318015873015873\n",
      "NDCG@5:   0.8468965\n",
      "NDCG@10:  0.83545035\n"
     ]
    }
   ],
   "source": [
    "print('MRR:     ', mrr_fin) \n",
    "print('MAP@3:   ', mapa3)\n",
    "print('MAP@10:  ', mapa10)\n",
    "print('NDCG@5:  ', ndcga5)  \n",
    "print('NDCG@10: ', ndcga10)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
