{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 15:44:08.911774: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 15:44:09.027643: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-30 15:44:09.520468: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/baran-tomik/bin/miniconda3/envs/tf/lib/\n",
      "2024-04-30 15:44:09.520565: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/baran-tomik/bin/miniconda3/envs/tf/lib/\n",
      "2024-04-30 15:44:09.520572: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.10.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.metrics import RSquare\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision - MAP@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified from:\n",
    "# author: Ben Hamner\n",
    "# author's github: benhamner\n",
    "# link to github: https://github.com/benhamner/Metrics/blob/master/Python/ml_metrics/average_precision.py \n",
    "\n",
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    apk_sum = 0.0\n",
    "    for user in actual:\n",
    "        if user in predicted:\n",
    "            apk_sum += apk(actual[user], predicted[user], k)\n",
    "\n",
    "    return apk_sum / len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Reciprocal Rank - MRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr(actual, predicted):\n",
    "    mrr_sum = 0.0\n",
    "    for user in actual:\n",
    "        if user in predicted:\n",
    "            rank = 1\n",
    "            for movie in predicted[user]:\n",
    "                if movie in actual[user]:\n",
    "                    mrr_sum += 1.0 / rank\n",
    "                    break\n",
    "                rank += 1\n",
    "    return mrr_sum / len(actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 25m Added IMDb context\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_added_imdb_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m/'\n",
    "# nn_model_path = '../model/arch5_25m_added_imdb_context_max_abs_scaler_gc_trained.keras'\n",
    "# scaler_file = '25m_added_imdb_context_scaler.pkl'\n",
    "\n",
    "# 25m MovieLens context - label encode just 'holiday'\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_movielens_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m_movielens_context/'\n",
    "# nn_model_path = '../model/arch5_25m_movielens_context_max_abs_scaler_gc_2_trained.keras'\n",
    "# scaler_file = '25m_movielens_context_scaler.pkl'\n",
    "\n",
    "# ## 25m No context - do not label encode any data\n",
    "# test_split_data_path = 'eval_data/test_split_25ml_no_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/25m_no_context/'\n",
    "# nn_model_path = '../model/arch5_25m_no_context_max_abs_scaler_gc_trained.keras'\n",
    "# scaler_file = '25m_no_context_scaler.pkl'\n",
    "\n",
    "# # ## 1m No context - do not label encode any data\n",
    "# test_split_data_path = 'eval_data/test_split_1ml_no_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/1m_no_context/'\n",
    "# nn_model_path = '../model/arch5_1m_no_context_max_abs_scaler_gc_trained.keras'\n",
    "# scaler_file = '1m_no_context_scaler.pkl'\n",
    "\n",
    "# # # ## 1m MovieLens context - label encode just 'holiday' and 'user_gender'\n",
    "# test_split_data_path = 'eval_data/test_split_1ml_movielens_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/1m_movielens_context/'\n",
    "# nn_model_path = '../model/arch5_1m_movielens_context_max_abs_scaler_gc_trained.keras'\n",
    "# scaler_file = '1m_movielens_context_scaler.pkl'\n",
    "\n",
    "# # ## 1m Added IMDb context\n",
    "# test_split_data_path = 'eval_data/test_split_1ml_added_imdb_context.csv'\n",
    "# recsys_data_path = '../data/transform_data/1m/'\n",
    "# nn_model_path = '../model/arch5_1m_added_imdb_context_max_abs_scaler_gc_trained.keras'\n",
    "# scaler_file = '1m_added_imdb_context_scaler.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2857</td>\n",
       "      <td>2268</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1172</td>\n",
       "      <td>2710</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5376</td>\n",
       "      <td>3681</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4362</td>\n",
       "      <td>246</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2197</td>\n",
       "      <td>246</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100016</th>\n",
       "      <td>4253</td>\n",
       "      <td>1348</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100017</th>\n",
       "      <td>3367</td>\n",
       "      <td>2080</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100018</th>\n",
       "      <td>261</td>\n",
       "      <td>3698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100019</th>\n",
       "      <td>2777</td>\n",
       "      <td>1665</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100020</th>\n",
       "      <td>3885</td>\n",
       "      <td>2746</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100021 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating\n",
       "0          2857      2268       4\n",
       "1          1172      2710       3\n",
       "2          5376      3681       5\n",
       "3          4362       246       5\n",
       "4          2197       246       4\n",
       "...         ...       ...     ...\n",
       "100016     4253      1348       2\n",
       "100017     3367      2080       4\n",
       "100018      261      3698       1\n",
       "100019     2777      1665       2\n",
       "100020     3885      2746       2\n",
       "\n",
       "[100021 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = pd.read_csv(test_split_data_path)\n",
    "test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 15:44:10.351647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.373973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.374142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.374660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 15:44:10.375113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.375243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.375356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.432214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.432378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.432494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-04-30 15:44:10.432587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 180 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "# number of users to evaluate\n",
    "n_users = 10\n",
    "# number of recommendations to make\n",
    "top_k = 10\n",
    "# lowest rating to consider as a positive recommendation\n",
    "low_rating = 4.0\n",
    "\n",
    "# sort users by number of ratings\n",
    "test_ratings_all_users = test_ratings['user_id'].value_counts().index.tolist()[:n_users]\n",
    "\n",
    "nn_model = load_model(nn_model_path, custom_objects={'RSquare': RSquare()}, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(data):\n",
    "    print(data.shape)\n",
    "    # actor_label_encoder = joblib.load(recsys_data_path + 'actor_label_encoder.pkl')\n",
    "    # directors_label_encoder = joblib.load(recsys_data_path + 'directors_label_encoder.pkl')\n",
    "    # holiday_label_encoder = joblib.load(recsys_data_path + 'holiday_label_encoder.pkl')\n",
    "    # titleType_label_encoder = joblib.load(recsys_data_path + 'titleType_label_encoder.pkl')\n",
    "    # user_gender_label_encoder = joblib.load(recsys_data_path + 'user_gender_label_encoder.pkl')\n",
    "\n",
    "    # Load scaler\n",
    "    scaler = joblib.load(recsys_data_path + scaler_file)\n",
    "\n",
    "    # Label encode data\n",
    "    # data['actor'] = actor_label_encoder.transform(data['actor'])\n",
    "    # data['directors'] = directors_label_encoder.transform(data['directors'])\n",
    "    # data['holiday'] = holiday_label_encoder.transform(data['holiday'])\n",
    "    # data['titleType'] = titleType_label_encoder.transform(data['titleType'])\n",
    "    # data['user_gender'] = user_gender_label_encoder.transform(data['user_gender'])\n",
    "\n",
    "\n",
    "    # Return scaled data\n",
    "    return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4169, 1680, 1941, 1181, 4277, 889, 5795, 2063, 2909, 3391]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings_all_users  # 1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 2)\n",
      "(164, 2)\n",
      "(162, 2)\n",
      "(153, 2)\n",
      "(150, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 2)\n",
      "(137, 2)\n",
      "(135, 2)\n",
      "(133, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/baran-tomik/bin/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MaxAbsScaler from version 1.2.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "actual = {}\n",
    "predicted = {}\n",
    "\n",
    "for user_id in test_ratings_all_users:\n",
    "\n",
    "    user_test_ratings = test_ratings[test_ratings['user_id'] == user_id]\n",
    "\n",
    "    actual_ratings = user_test_ratings[user_test_ratings['rating'] >= low_rating]\n",
    "    actual[user_id] = actual_ratings['movie_id'].tolist()\n",
    "\n",
    "    scaled_user_test_ratings = scale_data(user_test_ratings.drop(['rating'], axis=1))\n",
    "    movie_indices = user_test_ratings['movie_id'].values\n",
    "\n",
    "    predictions = nn_model.predict(scaled_user_test_ratings, verbose=0).flatten()\n",
    "\n",
    "    predicted_movies = pd.DataFrame({'movie_id': movie_indices, 'rating': predictions})\n",
    "    predicted_movies = predicted_movies.sort_values(by='rating', ascending=False)\n",
    "    predicted[user_id] = predicted_movies['movie_id'][:top_k].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile 1 - 72315 | profile 2 - 80974 | profile 3 - 107650"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MRR\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mrr_fin \u001b[38;5;241m=\u001b[39m \u001b[43mmrr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMRR: \u001b[39m\u001b[38;5;124m'\u001b[39m, mrr_fin) \n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# MRR\n",
    "mrr_fin = mrr(actual, predicted)\n",
    "print('MRR: ', mrr_fin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@3:   0.5166666666666666\n",
      "MAP@10:  0.4833373015873015\n"
     ]
    }
   ],
   "source": [
    "# MAP@K\n",
    "mapa3 = mapk(actual, predicted, 3)\n",
    "mapa10 = mapk(actual, predicted, 10)\n",
    "print('MAP@3:  ', mapa3)\n",
    "print('MAP@10: ', mapa10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
