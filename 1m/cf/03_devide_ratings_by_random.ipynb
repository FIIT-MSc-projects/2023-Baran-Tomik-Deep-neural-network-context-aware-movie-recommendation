{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "# import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import spatial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1671</td>\n",
       "      <td>3342</td>\n",
       "      <td>5</td>\n",
       "      <td>974713449</td>\n",
       "      <td>Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2569</td>\n",
       "      <td>3929</td>\n",
       "      <td>4</td>\n",
       "      <td>973911951</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3747</td>\n",
       "      <td>1639</td>\n",
       "      <td>4</td>\n",
       "      <td>966138457</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3821</td>\n",
       "      <td>3702</td>\n",
       "      <td>4</td>\n",
       "      <td>974759703</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5173</td>\n",
       "      <td>3147</td>\n",
       "      <td>5</td>\n",
       "      <td>961886251</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575276</th>\n",
       "      <td>1074</td>\n",
       "      <td>3363</td>\n",
       "      <td>5</td>\n",
       "      <td>974939651</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575277</th>\n",
       "      <td>3618</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>966600709</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575278</th>\n",
       "      <td>3619</td>\n",
       "      <td>1732</td>\n",
       "      <td>4</td>\n",
       "      <td>966585395</td>\n",
       "      <td>Comedy|Crime|Mystery|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575279</th>\n",
       "      <td>1737</td>\n",
       "      <td>2060</td>\n",
       "      <td>5</td>\n",
       "      <td>976062754</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575280</th>\n",
       "      <td>494</td>\n",
       "      <td>575</td>\n",
       "      <td>4</td>\n",
       "      <td>976216289</td>\n",
       "      <td>ForChildren|Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>575281 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating  timestamp                         genres\n",
       "0          1671      3342       5  974713449                      Drama|War\n",
       "1          2569      3929       4  973911951                         Comedy\n",
       "2          3747      1639       4  966138457                  Drama|Romance\n",
       "3          3821      3702       4  974759703                  Action|Sci-Fi\n",
       "4          5173      3147       5  961886251                 Drama|Thriller\n",
       "...         ...       ...     ...        ...                            ...\n",
       "575276     1074      3363       5  974939651                   Comedy|Drama\n",
       "575277     3618        17       4  966600709                  Drama|Romance\n",
       "575278     3619      1732       4  966585395  Comedy|Crime|Mystery|Thriller\n",
       "575279     1737      2060       5  976062754                         Comedy\n",
       "575280      494       575       4  976216289             ForChildren|Comedy\n",
       "\n",
       "[575281 rows x 5 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_depth = '../..'\n",
    "\n",
    "with open(file_depth + '/config/data_1m_config.json') as config_file:\n",
    "    config = json.load(config_file)\n",
    "\n",
    "movies_data_path = config['original_csv_movies_data']\n",
    "ratings_data_path = config['original_csv_ratings_data']\n",
    "users_data_path = config['original_csv_users_data']\n",
    "\n",
    "movies = pd.read_csv(file_depth + movies_data_path)\n",
    "ratings = pd.read_csv(file_depth + ratings_data_path)\n",
    "users = pd.read_csv(file_depth + users_data_path)\n",
    "\n",
    "# get all unique genres\n",
    "unique_genres = movies['genres'].str.split('|', expand=True).stack().unique()\n",
    "\n",
    "# ratings of 4 or 5\n",
    "filtered_ratings = ratings[(ratings['rating'] == 4) | (ratings['rating'] == 5)]\n",
    "\n",
    "final_ratings = filtered_ratings.merge(movies, on='movie_id', how='inner').drop(columns=['title', 'movie_year'])\n",
    "\n",
    "# shuffle data and reset index \n",
    "final_ratings = shuffle(final_ratings)\n",
    "final_ratings.reset_index(inplace=True, drop=True)\n",
    "\n",
    "final_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rating_data_deviders/row_indexes.json') as row_indexes_file:\n",
    "    row_indexes = json.load(row_indexes_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly shuffled ratings will be divided into 12 parts, in each in 48000 ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'01': {'start': '0', 'end': '48000'},\n",
       " '02': {'start': '48001', 'end': '96000'},\n",
       " '03': {'start': '96001', 'end': '144000'},\n",
       " '04': {'start': '144001', 'end': '192000'},\n",
       " '05': {'start': '192001', 'end': '240000'},\n",
       " '06': {'start': '240001', 'end': '288000'},\n",
       " '07': {'start': '288001', 'end': '336000'},\n",
       " '08': {'start': '336001', 'end': '384000'},\n",
       " '09': {'start': '384001', 'end': '432000'},\n",
       " '10': {'start': '432001', 'end': '480000'},\n",
       " '11': {'start': '480001', 'end': '528000'},\n",
       " '12': {'start': '528001', 'end': '575281'}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = []\n",
    "\n",
    "for one_split in row_indexes:\n",
    "\n",
    "    start_index = int(row_indexes[one_split]['start'])\n",
    "    end_index = int(row_indexes[one_split]['end'])\n",
    "    filtered_by_indexes = final_ratings.iloc[start_index:end_index]\n",
    "    splits.append(filtered_by_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits: 12\n",
      "------------------------------------\n",
      "Split 1: 48000 rows\n",
      "Split 2: 47999 rows\n",
      "Split 3: 47999 rows\n",
      "Split 4: 47999 rows\n",
      "Split 5: 47999 rows\n",
      "Split 6: 47999 rows\n",
      "Split 7: 47999 rows\n",
      "Split 8: 47999 rows\n",
      "Split 9: 47999 rows\n",
      "Split 10: 47999 rows\n",
      "Split 11: 47999 rows\n",
      "Split 12: 47280 rows\n",
      "------------------------------------\n",
      "Total rows: 575270\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of splits: {len(splits)}\")\n",
    "print('------------------------------------')\n",
    "count = 0\n",
    "for i in range(len(splits)):\n",
    "    print(f\"Split {i + 1}: {len(splits[i])} rows\")\n",
    "    count += len(splits[i])\n",
    "\n",
    "print('------------------------------------')\n",
    "\n",
    "print(f\"Total rows: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save splits to csv files \n",
    "for index, split in enumerate(splits):\n",
    "    split.to_csv(f\"rating_user_data/splits/rating_split{index + 1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_present_in_all_splits(splits):\n",
    "    common_users = set(splits[0]['user_id'])\n",
    "\n",
    "    for df in splits[1:]:\n",
    "        current_users = set(df['user_id'])\n",
    "        common_users = common_users.intersection(current_users)\n",
    "        \n",
    "    print(f\"Number of users present in all splits: {len(common_users)}\")\n",
    "    print(f\"Returning the first user_id in the list: {list(common_users)[0]}\")\n",
    "    return list(common_users)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set(split, unique_genres):\n",
    "    \n",
    "    user_vectors = {}\n",
    "    grouped_split_data = split.groupby('user_id')\n",
    "\n",
    "    for user_id, group in grouped_split_data:\n",
    "        user_genre_vectors = {}\n",
    "        \n",
    "        for genre in unique_genres:\n",
    "            split_genres = group['genres'].str.split('|')\n",
    "            movies_in_genre_count = split_genres.apply(lambda x: genre in x).sum()\n",
    "            user_genre_vectors[genre] = int(movies_in_genre_count)\n",
    "\n",
    "        user_vectors[user_id] = user_genre_vectors\n",
    "        \n",
    "    return user_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_from_sets(target_user_id, splits, unique_genres):\n",
    "\n",
    "    similarities = []\n",
    "    sets_of_categories_for_each_user = []\n",
    "\n",
    "    for split in tqdm(splits):\n",
    "        user_category_set = create_set(split, unique_genres)\n",
    "\n",
    "        if target_user_id in user_category_set:\n",
    "            target_user = list(user_category_set[target_user_id].values())\n",
    "            one_set_similarities = {}\n",
    "\n",
    "            for user_id, user_data in user_category_set.items():\n",
    "                if user_id != target_user_id:  # Skip if it's the target user\n",
    "                    user_x = list(user_data.values())\n",
    "                    similarity = 1 - spatial.distance.cosine(target_user, user_x)\n",
    "                    one_set_similarities[user_id] = similarity\n",
    "        else:\n",
    "            print(f\"User with id {target_user_id} is not in user_category_set\") \n",
    "            exit()\n",
    "        \n",
    "\n",
    "        sets_of_categories_for_each_user.append(user_category_set)\n",
    "        similarities.append(one_set_similarities)\n",
    "    \n",
    "    return similarities, sets_of_categories_for_each_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users present in all splits: 4084\n",
      "Returning the first user_id in the list: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [07:30<00:00, 37.52s/it]\n"
     ]
    }
   ],
   "source": [
    "target_user_id = get_users_present_in_all_splits(splits)\n",
    "similarities, sets = get_similarity_from_sets(target_user_id, splits, unique_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_sets_of_categories_file = 'rating_user_data/sets_of_categories_for_each_user.json'\n",
    "save_similarities_file = f\"rating_user_data/similarities_to_user_{target_user_id}.json\"\n",
    "\n",
    "\n",
    "with open(save_sets_of_categories_file, 'w') as fp:\n",
    "    json.dump(sets, fp)\n",
    "\n",
    "with open(save_similarities_file, 'w') as fp:\n",
    "    json.dump(similarities, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
